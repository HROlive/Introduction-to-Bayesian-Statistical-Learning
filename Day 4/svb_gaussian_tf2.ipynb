{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Variational Bayes\n",
    "=======================\n",
    "\n",
    "This notebook implements Example 1 from the FMRIB tutorial on Variational Bayes II: Stochastic Variational Bayes (\"fitting a Gaussian distribution).\n",
    "\n",
    "We assume we have data drawn from a Gaussian distribution with true mean $\\mu$ and true precision $\\beta$:\n",
    "\n",
    "$$\n",
    "P(y_n | \\mu, \\beta) = \\frac{\\sqrt{\\beta}}{\\sqrt{2\\pi}} \\exp{-\\frac{\\beta}{2} (y_n - \\mu)^2}\n",
    "$$\n",
    "\n",
    "One interpretation of this is that our data consists of repeated measurements of a fixed value ($\\mu$) combined with Gaussian noise with standard deviation $\\frac{1}{\\sqrt{\\beta}}$.\n",
    "\n",
    "Here's how we can generate some sample data from this model in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data samples are:\n",
      "[41.69330425 43.22760142 42.04227699 41.8726123  42.10124698 42.06148383\n",
      " 43.07223824 42.95316759 41.38239292 42.80939571 44.77113522 40.59558767\n",
      " 42.94639899 42.60768533 41.44394187 42.78759534 39.98116589 42.5661791\n",
      " 42.48842924 40.99124449 41.89709575 43.11330919 41.708735   42.87831323\n",
      " 41.08147171 41.71958743 42.46591807 41.6370583  41.8648694  43.29941234\n",
      " 41.53153621 42.27939892 42.73532511 42.80090713 42.41404559 42.16952383\n",
      " 40.97795771 43.72456543 42.93386718 42.75672866 41.39694193 39.7078651\n",
      " 43.91464577 43.33962568 40.09870405 43.33660874 40.91621448 40.6448031\n",
      " 43.04706312 42.12147857 41.38607984 42.21791959 41.12890543 41.97966952\n",
      " 41.00969587 42.84116868 41.5972026  41.2236852  41.58269978 42.08416207\n",
      " 41.91320553 39.37739812 41.77886506 41.78896676 41.96599989 40.52331769\n",
      " 41.99641274 40.43126556 42.61890785 41.12090487 43.18604389 40.98318213\n",
      " 43.23229514 44.00299414 41.38041941 43.05466329 42.01280297 40.38765589\n",
      " 43.44037223 42.01792412 42.14212663 40.49368043 42.13380001 41.58396877\n",
      " 41.00460675 43.25897542 40.55767639 41.25966307 41.61961251 41.99744515\n",
      " 41.5689065  40.32893455 40.63016246 42.22022195 42.37517688 40.98311719\n",
      " 41.13315559 41.54570082 42.34490129 40.07093031]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Ground truth parameters\n",
    "# We infer the precision, BETA, but it is useful to\n",
    "# derive the variance and standard deviation from it\n",
    "MU_TRUTH = 42\n",
    "BETA_TRUTH = 1.0\n",
    "VAR_TRUTH = 1/BETA_TRUTH\n",
    "STD_TRUTH = np.sqrt(VAR_TRUTH)\n",
    "\n",
    "# Observed data samples are generated by Numpy from the ground truth\n",
    "# Gaussian distribution. Reducing the number of samples should make\n",
    "# the inference less 'confident' - i.e. the output variances for\n",
    "# MU and BETA will increase\n",
    "N = 100\n",
    "DATA = np.random.normal(MU_TRUTH, STD_TRUTH, [N])\n",
    "print(\"Data samples are:\")\n",
    "print(DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the 'signal + noise' interpretation we can view this as noisy measurements (red crosses) of a constant signal (green line):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1458624f6c10>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(DATA, \"rx\")\n",
    "plt.plot([MU_TRUTH] * N, \"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priors: P(mu, log(1/beta)) = MVN([0.000000, 10000.000000], [[0.000000, 0], [0, 10000.000000]])\n"
     ]
    }
   ],
   "source": [
    "m0 = 0.0\n",
    "v0 = 10000.0\n",
    "b0 = 0.0\n",
    "w0 = 10000.0\n",
    "print(\"Priors: P(mu, log(1/beta)) = MVN([%f, %f], [[%f, 0], [0, %f]])\" % (m0, v0, b0, w0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with analytic Variational Bayes, we need to choose an approximate form for our priors and posteriors. However we have more freedom in the stochastic method since we are not limited by the requirement that the distributions be conjugate with respect to the likelihood. \n",
    "\n",
    "We will choose a multivariate normal distribution (MVN) over the two parameters $\\mu$ and $log(\\frac{1}{\\beta})$ for prior and posterior. Inferring the log of the noise variance is useful as it avoid the possibility of negative values during the optimization which would make the likelihood ill-defined.\n",
    "\n",
    "The choice of an MVN means that we can allow for covariance (correlation) between the noise and signal parameters. This is unlike the analytic case where the posterior had to be factorised over these two parameters.\n",
    "\n",
    "An MVN distribution for $N$ parameters is defined by a vector of $N$ mean values and an $N \\times N$ covariance matrix. For the prior we will use the following values:\n",
    "\n",
    "$$\\textbf{m}_0 = \\begin{bmatrix} \\mu_0 \\\\ b_0 \\end{bmatrix}$$\n",
    "\n",
    "$$\\textbf{C}_0 = \\begin{bmatrix} v_0 & 0 \\\\ 0 & w_0 \\end{bmatrix}$$\n",
    "\n",
    "Note that we are not assuming any prior covariance. \n",
    "\n",
    "We define some suitable relatively uninformative prior values here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic VB is based around minimising the free energy so we will need to implement the calculation of the free energy. We will be using the TensorFlow framework to perform the minimisation so the calculation must be in terms of tensors (multidimensional arrays). In our case the following constant tensors must be defined (where $N$ is the number of data values we have:\n",
    "\n",
    " - Data samples: $[N]$\n",
    " - Prior mean: $[2]$\n",
    " - Prior covariance: $[2 \\times 2]$\n",
    "\n",
    "We must also define *variable* tensors for the posterior - TensorFlow will allow these to change during the optimization in order to minimise the cost (free energy):\n",
    "\n",
    " - Posterior mean: $[2]$\n",
    " - Posterior covariance: $[2 \\times 2]$\n",
    "\n",
    "The posterior covariance must be a positive-definite matrix - since the optimizer does not know this, it is possible that invalid values may arise and the optimization will fail. To get around this restriction we build the covariance matrix from its Chlolesky decomposition.\n",
    "\n",
    "$$\\textbf{C} = (\\textbf{C}_{chol})^T\\textbf{C}_{chol}$$\n",
    "\n",
    "$\\textbf{C}_{chol}$ must have positive diagonal elements, so we define the underlying variables for these elements in terms of the log and then form the full $\\textbf{C}_{chol}$ matrix as a sum of the exponentials of the log-diagonal elements, and independent variables for the off-diagonal components.\n",
    "\n",
    "The code for this is below. Note that we need to define initial values for the posterior variables. It turns out that in the stochastic method it is important that the initial poster variance is not too large so although the prior is not informative, the initial posterior is. \n",
    "\n",
    "The next requirement is to be able to obtain a sample of *predicted* data values from the posterior. In stochastic VB this is used to approximate the integrals in the calculation of the free energy. It is *not* related to the number of data samples we have. Smaller values give quicker calculation, but may result in a noisy, non-convergent optimization. We'll start off with a sample size of 5, but you can change this later if you want.\n",
    "\n",
    "Note the use of the 'reparameterization trick' to express the samples as the scaling of a fixed MVN distribution - this improves the ability of the optimizer to choose better values for the next iteration.\n",
    "\n",
    "Next we need to implement the free energy calculation. This is the sum of the reconstruction loss (the extent to which the posterior matches the data) and the latent loss (the extent to which the posterior matches the prior). Let's do the reconstruction loss first which is the expected value of the log-likelihood across the posterior distribution. Remember that the expectation integral is being approximated using the samples we have from the posterior. So we evaluate the log-likelihood for *each* set of samples and then take the mean across all the samples.\n",
    "\n",
    "On to the latent loss, this is the log-KL divergence between the posterior and prior. Since\n",
    "both our prior and posterior are MVN distributions, we can use a known analytic result as\n",
    "given in the tutorial:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 17:12:07.590629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38284 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0\n",
      "2023-03-19 17:12:07.592452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38284 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:44:00.0, compute capability: 8.0\n",
      "2023-03-19 17:12:07.594212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38284 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:84:00.0, compute capability: 8.0\n",
      "2023-03-19 17:12:07.595828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38284 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c4:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "data = tf.constant(DATA, dtype=tf.float32)\n",
    "prior_means = tf.constant([m0, v0], dtype=tf.float32)\n",
    "prior_covariance = tf.constant([[v0, 0.0], [0.0, w0]], dtype=tf.float32)\n",
    "\n",
    "chol_off_diag = tf.Variable([[0, 0], [0, 0]], dtype=tf.float32) ###variable\n",
    "\n",
    "post_means_init = [0.0, 0.0]\n",
    "post_covariance_init = [[1.0, 0.0], [0.0, 1.0]]\n",
    "\n",
    "chol_log_diag = tf.Variable(tf.math.log(tf.linalg.diag_part(post_covariance_init)), dtype=tf.float32) ###variable\n",
    "\n",
    "post_means = tf.Variable(post_means_init, dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "def cost_fun():\n",
    "#   print(\"here\\n\")\n",
    "    N=100\n",
    "    S=5\n",
    "# Comment in this line if you do NOT want to infer parameter covariances\n",
    "#chol_off_diag = tf.constant([[0, 0], [0, 0]], dtype=tf.float32)\n",
    "\n",
    "    chol_diag = tf.linalg.diag(tf.math.sqrt(tf.math.exp(chol_log_diag)))\n",
    "    post_covariance_chol = tf.math.add(chol_diag, tf.linalg.band_part(chol_off_diag, -1, 0))\n",
    "\n",
    "    post_covariance = tf.matmul(tf.transpose(post_covariance_chol), post_covariance_chol) \n",
    "\n",
    "    eps = tf.random.normal((2, S), 0, 1, dtype=tf.float32)\n",
    "#   print(\"here\\n\")\n",
    "# Start off each sample with the current posterior mean\n",
    "# post_samples is now a tensor of shape [2, n_samples]\n",
    "    samples = tf.tile(tf.reshape(post_means, [2, 1]), [1, S])\n",
    "\n",
    "# Now add the random sample scaled by the covariance\n",
    "    post_samples = tf.add(samples, tf.matmul(post_covariance_chol, eps)) \n",
    "\n",
    "    mu_samples = post_samples[0]\n",
    " #   print(\"here\\n\")\n",
    "# Get the current estimate of the noise variance remembering that\n",
    "# we are inferring the log of the noise precision, beta\n",
    "    log_noise_var = -post_samples[1]\n",
    "    noise_var = tf.math.exp(log_noise_var)\n",
    "#    print(\"here\\n\")\n",
    "# Each sample value predicts the full set of values in the data sample.\n",
    "# For our constant-signal model, the prediction is simply a set of \n",
    "# constant values. The prediction tensor will have shape [S, N]\n",
    "# where S is the sample size and N is the number of data values\n",
    "    prediction = tf.tile(tf.reshape(mu_samples, [S, 1]), [1, N])\n",
    "#    print(\"here\\n\")\n",
    "# To calculate the likelihood we need the sum of the squared difference between the data  \n",
    "# and the prediction. This gives a value for each posterior sample so has shape [S]\n",
    "#    print(data.shape, prediction.shape)\n",
    "    sum_square_diff = tf.reduce_sum(tf.math.square(data - prediction), axis=-1)\n",
    "    \n",
    "# Now we calculate the likelihood for each posterior sample (shape [S])\n",
    "# Note that we are ignoring constant factors such as 2*PI here as they \n",
    "# are just an fixed offset and do not affect the optimization \n",
    "    log_likelihood = 0.5 * (-log_noise_var * tf.cast(N,dtype=tf.float32) - sum_square_diff / noise_var)\n",
    "\n",
    "# Finally to evaluate the expectation value we take the mean across all the posterior\n",
    "# samples\n",
    "    reconstr_loss = -tf.reduce_mean(log_likelihood)\n",
    "\n",
    "    C = post_covariance\n",
    "    C0 = prior_covariance\n",
    "\n",
    "    m_minus_m0 = tf.reshape(tf.subtract(post_means, prior_means), [-1, 1])\n",
    "    m_minus_m0_T = tf.reshape(tf.subtract(post_means, prior_means), [1, -1])\n",
    "\n",
    "    C0_inv = tf.linalg.inv(C0)\n",
    "\n",
    "    term1 = tf.linalg.trace(tf.matmul(C0_inv, C))\n",
    "    term2 = -tf.math.log(tf.linalg.det(C) / tf.linalg.det(C0))\n",
    "\n",
    "# Size of the MVN distribution\n",
    "    term3 = -2\n",
    "    term4 = tf.matmul(tf.matmul(m_minus_m0_T, C0_inv), m_minus_m0)\n",
    "#   print(\"here\\n\")         \n",
    "    latent_loss = 0.5 * (term1 + term2 + term3 + term4)\n",
    " #   print(\"here\\n\")\n",
    "    noise_var = tf.math.exp(log_noise_var)\n",
    "\n",
    "# Each sample value predicts the full set of values in the data sample.\n",
    "# For our constant-signal model, the prediction is simply a set of \n",
    "# constant values. The prediction tensor will have shape [S, N]\n",
    "# where S is the sample size and N is the number of data values\n",
    "#    print(\"here\\n\")\n",
    "    prediction = tf.tile(tf.reshape(mu_samples, [S, 1]), [1, N])\n",
    "#    print(prediction.shape,\" prediction shape\\n\")\n",
    "\n",
    "# To calculate the likelihood we need the sum of the squared difference between the data  \n",
    "# and the prediction. This gives a value for each posterior sample so has shape [S]\n",
    "    sum_square_diff = tf.reduce_sum(tf.math.square(data - prediction), axis=-1)\n",
    "\n",
    "# Now we calculate the likelihood for each posterior sample (shape [S])\n",
    "# Note that we are ignoring constant factors such as 2*PI here as they \n",
    "# are just an fixed offset and do not affect the optimization \n",
    "    log_likelihood = 0.5 * (-log_noise_var * tf.cast(N,dtype=tf.float32) - sum_square_diff / noise_var)\n",
    "\n",
    "# Finally to evaluate the expectation value we take the mean across all the posterior\n",
    "# samples\n",
    "    reconstr_loss = -tf.reduce_mean(log_likelihood)\n",
    "\n",
    "    cost=reconstr_loss + latent_loss\n",
    "\n",
    "    return cost\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize the posterior we need to iteratively minimise the cost using TensorFlow's built in gradient optimizer. We use the Adam optimizer for this, which is a refinement of the standard Gradient Descent optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cac2bb6b7b14c3296e09193bc5b5d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch::   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 17:12:08.668453: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-03-19 17:12:08.672920: I tensorflow/core/util/cuda_solvers.cc:180] Creating CudaSolver handles for stream 0x2c9031d0\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.5)\n",
    "#minimizer = optimizer.minimize(cost)\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "cost_history = []\n",
    "for epoch in tqdm_notebook(range(5000), desc=\"Epoch:\"):\n",
    "    #sess.run(minimizer)\n",
    "\n",
    "    #cost_history.append(float(sess.run(cost)))\n",
    "    optimizer.minimize(cost_fun,var_list=[chol_off_diag,chol_log_diag,post_means])\n",
    "    #print(float(cost_fun()))\n",
    "    cost_history.append(float(cost_fun()))\n",
    "    #print(\"Epoch %i: posterior means=%s\" % (epoch+1, post_means))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should find our estimates for mu and beta are as expected, remembering that we chose\n",
    "to estimate $-\\log{\\beta}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate for mu: 41.934135 (variance: 0.023306)\n",
      "Estimate for beta: 0.962277\n"
     ]
    }
   ],
   "source": [
    "final_means = post_means\n",
    "chol_diag = tf.linalg.diag(tf.math.sqrt(tf.math.exp(chol_log_diag)))\n",
    "post_covariance_chol = tf.math.add(chol_diag, tf.linalg.band_part(chol_off_diag, -1, 0))\n",
    "post_covariance = tf.matmul(tf.transpose(post_covariance_chol), post_covariance_chol) \n",
    "final_covariance = post_covariance\n",
    "print(\"Estimate for mu: %f (variance: %f)\" % (final_means[0], final_covariance[0, 0]))\n",
    "print(\"Estimate for beta: %f\" % np.exp(final_means[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convergence of the minimisation in this case is rather slow - considering the simplicity of the problem. This is partly due to the large difference between the initial posterior and the true value for $\\mu$. However, frameworks like TensorFlow are not really optimized for inferring such a small number of parameters and the method. If we plot the cost history we can see that it gets stuck in a local minimum for some time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1455f818c5e0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cost_history)\n",
    "#plt.ylim(50000, 51000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot our inferred value of $\\mu$ with error bars $\\pm 2\\sigma$ derived from the inferred variance on this parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1455f8125460>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(DATA, \"rx\")\n",
    "plt.plot([MU_TRUTH] * N, \"g\")\n",
    "plt.plot([final_means[0]] * N, \"b\")\n",
    "plt.plot([final_means[0]+2*np.sqrt(final_covariance[0, 0])] * N, \"b--\")\n",
    "plt.plot([final_means[0]-2*np.sqrt(final_covariance[0, 0])] * N, \"b--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main advantage of the SVB approach is the flexibility - as well as losing the restriction to conjugate priors, it is also much easier to implement more advanced types of parameters and priors, for example global parameters or spatial regularization priors. While these can (and have been) incorporated into the analytic VB framework, they require update equations to be re-derived whereas the SVB method simply needs an expression for the cost which is generally more straightforward.\n",
    "\n",
    "Some things you might like to try with this example:\n",
    "\n",
    " - Do not infer the covariance between the parameters (see commented out code in the definition of the posterior). This generally makes the convergence less noisy.\n",
    " - Modify the number of samples and the learning rate and see how they affect the convergence\n",
    " - Try implementing the stochastic form of the latent loss rather than the analytic result for an MVN that we have used here (see Box 1 in the tutorial). This is necessary in cases where we do not assume an MVN structure for the prior and posterior. Essentially you need to calculate the log PDF for the prior and posterior for each sample and take the mean over all the samples.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyDeepLearning-1.1",
   "language": "python",
   "name": "pydeeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
